{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54cdf6a3-29fb-45a8-9705-13117d1befd1",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-07-17T09:32:48.737967Z",
     "shell.execute_reply.started": "2024-07-17T09:32:48.724614Z",
     "to_execute": "2024-07-17T09:32:48.702Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: harmony\n",
      "  Input Length: 72, Average Metrics: {'mse': 0.045293026603758335, 'crps': 0.09952614717185497}\n",
      "  Input Length: 144, Average Metrics: {'mse': 0.04575974158942699, 'crps': 0.09399256221950054}\n",
      "  Input Length: 288, Average Metrics: {'mse': 0.047408952936530115, 'crps': 0.10965233370661735}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse_metrics_line(line):\n",
    "    metrics = line.strip().split(',')\n",
    "    return {metric.split(':')[0].strip(): float(metric.split(':')[1].strip()) for metric in metrics}\n",
    "\n",
    "def process_results_file(file_path):\n",
    "    results = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    \n",
    "    for i in range(0, len(lines), 3):\n",
    "        if i+1 >= len(lines):  \n",
    "            break\n",
    "        if lines[i].strip() == '':  \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            model_info = lines[i].strip().split()\n",
    "            metrics_info = lines[i+1].strip()\n",
    "            # print(model_info )\n",
    "            # print(metrics_info)\n",
    "        except ValueError as e:\n",
    "            print(f\"ValueError at line {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if len(model_info) >= 3:\n",
    "            _, model_name, input_length = model_info[0], model_info[1], model_info[2]\n",
    "            input_length = int(input_length)\n",
    "            metrics = parse_metrics_line(metrics_info)\n",
    "\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                results[model_name][input_length][metric_name].append(metric_value)\n",
    "        else:\n",
    "            print(f\"Skipped line {i} due to incorrect format.\")\n",
    "\n",
    "\n",
    "    average_metrics = {model: {} for model in results}\n",
    "    for model in results:\n",
    "        for length in results[model]:\n",
    "            average_metrics[model][length] = {\n",
    "                metric_name: np.mean(values)\n",
    "                for metric_name, values in results[model][length].items()\n",
    "            }\n",
    "\n",
    "    return average_metrics\n",
    "\n",
    "file_path = 'result_Fisher.txt' \n",
    "average_metrics = process_results_file(file_path)\n",
    "\n",
    "for model, lengths_data in average_metrics.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    for length, metrics in lengths_data.items():\n",
    "        print(f\"  Input Length: {length}, Average Metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
